{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkhanks/Project_4_Machine_Learning/blob/main/Amyworkingupcolablast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s7N88W6Sfl-",
        "outputId": "44a22a21-9151-4840-8e04-513deb2c8d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from https://downloads.apache.org/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.5.1'\n",
        "spark_version = 'spark-3.5.5'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"RestaurantInspections\").getOrCreate()"
      ],
      "metadata": {
        "id": "peHjkh-nTekz"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path to your local CSV file\n",
        "file_path = \"/content/ARCHIVED__Restaurant_Inspection_Scores__2016-2019__20250310.csv\"  # Replace with your actual file path\n",
        "\n",
        "# Read CSV file into Spark DataFrame\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame to verify it loaded correctly\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ag0iCFFTsiJ",
        "outputId": "c605c807-20d1-4467-9164-1a769ac1aa0e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+-------------+--------------+--------------------+-----------------+------------------+--------------------+---------------------+---------------+--------------------+----------------+--------------------+--------------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "|business_id|       business_name|    business_address|business_city|business_state|business_postal_code|business_latitude|business_longitude|   business_location|business_phone_number|  inspection_id|     inspection_date|inspection_score|     inspection_type|        violation_id|violation_description|risk_category|Neighborhoods|SF Find Neighborhoods|Current Police Districts|Current Supervisor Districts|Analysis Neighborhoods|\n",
            "+-----------+--------------------+--------------------+-------------+--------------+--------------------+-----------------+------------------+--------------------+---------------------+---------------+--------------------+----------------+--------------------+--------------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "|      85936|        Laurel Court|        950 Mason St|San Francisco|            CA|               94108|             NULL|              NULL|                NULL|          14155775000| 85936_20170925|09/25/2017 12:00:...|             100|Routine - Unsched...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|       5827|HILLCREST ELEMENT...|      810 SILVER Ave|San Francisco|            CA|               94134|        37.729016|       -122.419253|POINT (-122.41925...|          14155464722|  5827_20170224|02/24/2017 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|           92|                   92|                       2|                           2|                     7|\n",
            "|      94910|       Ike's Kitchen|    800 Van Ness Ave|San Francisco|            CA|               94109|             NULL|              NULL|                NULL|                 NULL| 94910_20180530|05/30/2018 12:00:...|            NULL|New Ownership - F...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|      64667|  Jasmine Rae Bakery| 1890 Bryant St #309|San Francisco|            CA|               94110|        37.763156|       -122.410351|POINT (-122.41035...|                 NULL| 64667_20170814|08/14/2017 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|           53|                   53|                       3|                           2|                    20|\n",
            "|      97722|  THE CHURRO FACTORY|       PIER 39  K-01|San Francisco|            CA|               94133|             NULL|              NULL|                NULL|                 NULL| 97722_20181217|12/17/2018 12:00:...|              96|Routine - Unsched...|97722_20181217_10...| Unclean or degrad...|     Low Risk|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|      87203|          The Morris|    2501 Mariposa St|San Francisco|            CA|               94110|             NULL|              NULL|                NULL|          14150710693| 87203_20171106|11/06/2017 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|       1710|Emporio Rulli Il ...|     225 Stockton St|San Francisco|            CA|               94108|        37.787936|       -122.406712|POINT (-122.40671...|                 NULL|  1710_20180423|04/23/2018 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|           19|                   19|                       6|                           3|                     8|\n",
            "|      92928|       Cafe Reveille|      201 Steiner St|San Francisco|            CA|               94117|             NULL|              NULL|                NULL|                 NULL| 92928_20180118|01/18/2018 12:00:...|            NULL|    New Construction|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|      90840|Steep Creamery & Tea|270 Brannan St., ...|San Francisco|            CA|               94107|             NULL|              NULL|                NULL|                 NULL| 90840_20171017|10/17/2017 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|        272|       ON THE BRIDGE|1581 Webster St #206|San Francisco|            CA|               94115|        37.785227|       -122.431472|POINT (-122.43147...|          14155927765|   272_20180611|06/11/2018 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|          101|                  101|                       4|                          11|                    15|\n",
            "|      92530|      Taqueria Zorro|    308 Columbus Ave|San Francisco|            CA|               94133|             NULL|              NULL|                NULL|          14155399677| 92530_20190823|08/23/2019 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|     100879|LORENZO'S OF NEW ...|        2109 POLK ST|San Francisco|            CA|               94109|             NULL|              NULL|                NULL|          14150980339|100879_20190611|06/11/2019 12:00:...|            NULL|       New Ownership|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|      95023|             Sakesan|      1400 Ocean Ave|San Francisco|            CA|               94112|             NULL|              NULL|                NULL|                 NULL| 95023_20180510|05/10/2018 12:00:...|              92|Routine - Unsched...|95023_20180510_10...| Wiping cloths not...|     Low Risk|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|      93362|       Cafe Valencia|   1252 Valencia St.|San Francisco|            CA|               94110|             NULL|              NULL|                NULL|                 NULL| 93362_20190426|04/26/2019 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|       3072|HOTEL UTAH SALOON...|         500 04th St|San Francisco|            CA|               94107|        37.779522|       -122.398104|POINT (-122.39810...|                 NULL|  3072_20180309|03/09/2018 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|           32|                   32|                       1|                          10|                    34|\n",
            "|      94977|94977 Portables 2...|24 Willie Mays Pl...|San Francisco|            CA|               94107|             NULL|              NULL|                NULL|                 NULL| 94977_20180911|09/11/2018 12:00:...|              96|Routine - Unsched...|94977_20180911_10...| Inadequate and in...|Moderate Risk|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|     101175|         THE UP & UP|      1268 GRANT AVE|San Francisco|            CA|               94133|             NULL|              NULL|                NULL|          14155379736|101175_20190703|07/03/2019 12:00:...|            NULL|New Ownership - F...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "|       3838|         CAFE PICARO|        3120 16th St|San Francisco|            CA|               94103|        37.764908|       -122.422442|POINT (-122.42244...|          14155434089|  3838_20180320|03/20/2018 12:00:...|            NULL|Reinspection/Foll...|                NULL|                 NULL|         NULL|           37|                   37|                       3|                           5|                    20|\n",
            "|      61056|Town School For Boys|     2750 JACKSON St|San Francisco|            CA|               94115|        37.791777|       -122.440355|POINT (-122.44035...|                 NULL| 61056_20161026|10/26/2016 12:00:...|            NULL|           Complaint|                NULL|                 NULL|         NULL|          102|                  102|                       4|                           6|                    30|\n",
            "|      94943|  94943 Hearth Table|24 Willie Mays Pl...|San Francisco|            CA|               94107|             NULL|              NULL|                NULL|                 NULL| 94943_20190412|04/12/2019 12:00:...|             100|Routine - Unsched...|                NULL|                 NULL|         NULL|         NULL|                 NULL|                    NULL|                        NULL|                  NULL|\n",
            "+-----------+--------------------+--------------------+-------------+--------------+--------------------+-----------------+------------------+--------------------+---------------------+---------------+--------------------+----------------+--------------------+--------------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows\n",
        "num_rows = df.count()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of rows in the DataFrame: {num_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i11KFlVDprlz",
        "outputId": "81a64537-8497-4625-fb3e-0b45a8aa089e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the DataFrame: 53973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4G4855bVTl-",
        "outputId": "1d5a4765-4e0d-415c-a746-97d9ead32117"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: integer (nullable = true)\n",
            " |-- business_name: string (nullable = true)\n",
            " |-- business_address: string (nullable = true)\n",
            " |-- business_city: string (nullable = true)\n",
            " |-- business_state: string (nullable = true)\n",
            " |-- business_postal_code: string (nullable = true)\n",
            " |-- business_latitude: double (nullable = true)\n",
            " |-- business_longitude: double (nullable = true)\n",
            " |-- business_location: string (nullable = true)\n",
            " |-- business_phone_number: long (nullable = true)\n",
            " |-- inspection_id: string (nullable = true)\n",
            " |-- inspection_date: string (nullable = true)\n",
            " |-- inspection_score: integer (nullable = true)\n",
            " |-- inspection_type: string (nullable = true)\n",
            " |-- violation_id: string (nullable = true)\n",
            " |-- violation_description: string (nullable = true)\n",
            " |-- risk_category: string (nullable = true)\n",
            " |-- Neighborhoods: integer (nullable = true)\n",
            " |-- SF Find Neighborhoods: integer (nullable = true)\n",
            " |-- Current Police Districts: integer (nullable = true)\n",
            " |-- Current Supervisor Districts: integer (nullable = true)\n",
            " |-- Analysis Neighborhoods: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Get the count of null values for each column to assist in determining which columns to drop before using dropna\n",
        "null_counts = df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "\n",
        "# Show the result\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSgd2tuav9Rn",
        "outputId": "15360ffa-cee1-46cc-d912-9f3ee8da40dd"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+----------------+-------------+--------------+--------------------+-----------------+------------------+-----------------+---------------------+-------------+---------------+----------------+---------------+------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "|business_id|business_name|business_address|business_city|business_state|business_postal_code|business_latitude|business_longitude|business_location|business_phone_number|inspection_id|inspection_date|inspection_score|inspection_type|violation_id|violation_description|risk_category|Neighborhoods|SF Find Neighborhoods|Current Police Districts|Current Supervisor Districts|Analysis Neighborhoods|\n",
            "+-----------+-------------+----------------+-------------+--------------+--------------------+-----------------+------------------+-----------------+---------------------+-------------+---------------+----------------+---------------+------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "|          0|            0|               0|            0|             0|                1186|            26498|             26498|            26513|                36301|            0|              0|           14432|              0|       13720|                13720|        13720|        26538|                26538|                   26526|                       26526|                 26526|\n",
            "+-----------+-------------+----------------+-------------+--------------+--------------------+-----------------+------------------+-----------------+---------------------+-------------+---------------+----------------+---------------+------------+---------------------+-------------+-------------+---------------------+------------------------+----------------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--business_name: removed because business_id provides the required unique values and is a numerical value which will work better for an ML model.\\\n",
        "--business_address: Removed because we didn't want to go as granular as specific addresses.\\\n",
        "--business_city: removed because all data comes from San Francisco City\\\n",
        "--business_state: removed because all data comes from the State of California\\\n",
        "--business_postal_code: Kept so we can see if postal code area has any part in predicting inspection scores.\\\n",
        "--business_latitude and business_longitude: removed both because they had over 26,000 null values and would greatly decrease our data.\\\n",
        "--business_location: removed because wasn't pertinent\\\n",
        "--business_phone_number: removed because it didn't fit the scope of our project\\\n",
        "--inspection_id\\\n",
        "--inspection_date\\\n",
        "--inspection_score\\\n",
        "--inspection_type\\\n",
        "--violation_id\\\n",
        "--violation_description\\\n",
        "--risk_category\\\n",
        "--Neighborhoods, SF Find Neighborhoods, Current Police Districts, Current Supervisor Districts, Analysis Neighborhoods: all removed because they had over 26000 null values and there wasn't any reference to what any of them meant"
      ],
      "metadata": {
        "id": "_pW7aGwwxNNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"business_name\", \"business_city\", \"business_address\",\"business_state\", \"business_latitude\", \"business_longitude\", \"business_phone_number\",\n",
        "                     'business_location', 'inspection_type', 'Neighborhoods', 'SF Find Neighborhoods',\n",
        "                     'Current Police Districts', 'Current Supervisor Districts', 'Analysis Neighborhoods']\n",
        "# Get the list of existing columns to remove (checking if they exist in the DataFrame)\n",
        "existing_columns_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
        "\n",
        "# Drop the columns that exist in the DataFrame\n",
        "prepared_df = df.drop(*existing_columns_to_remove)\n",
        "prepared_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC3u3q1stMFW",
        "outputId": "67632ed5-9849-42ef-c068-c77af3b58b72"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "|business_id|business_postal_code|  inspection_id|     inspection_date|inspection_score|        violation_id|violation_description|risk_category|\n",
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "|      85936|               94108| 85936_20170925|09/25/2017 12:00:...|             100|                NULL|                 NULL|         NULL|\n",
            "|       5827|               94134|  5827_20170224|02/24/2017 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      94910|               94109| 94910_20180530|05/30/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      64667|               94110| 64667_20170814|08/14/2017 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      97722|               94133| 97722_20181217|12/17/2018 12:00:...|              96|97722_20181217_10...| Unclean or degrad...|     Low Risk|\n",
            "|      87203|               94110| 87203_20171106|11/06/2017 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|       1710|               94108|  1710_20180423|04/23/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      92928|               94117| 92928_20180118|01/18/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      90840|               94107| 90840_20171017|10/17/2017 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|        272|               94115|   272_20180611|06/11/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      92530|               94133| 92530_20190823|08/23/2019 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|     100879|               94109|100879_20190611|06/11/2019 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      95023|               94112| 95023_20180510|05/10/2018 12:00:...|              92|95023_20180510_10...| Wiping cloths not...|     Low Risk|\n",
            "|      93362|               94110| 93362_20190426|04/26/2019 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|       3072|               94107|  3072_20180309|03/09/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      94977|               94107| 94977_20180911|09/11/2018 12:00:...|              96|94977_20180911_10...| Inadequate and in...|Moderate Risk|\n",
            "|     101175|               94133|101175_20190703|07/03/2019 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|       3838|               94103|  3838_20180320|03/20/2018 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      61056|               94115| 61056_20161026|10/26/2016 12:00:...|            NULL|                NULL|                 NULL|         NULL|\n",
            "|      94943|               94107| 94943_20190412|04/12/2019 12:00:...|             100|                NULL|                 NULL|         NULL|\n",
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_drop=prepared_df.dropna()\n",
        "df_drop.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Ga-jBzvKbw",
        "outputId": "e4be6b44-93ff-44da-a298-975e5ea65d2b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "|business_id|business_postal_code|  inspection_id|     inspection_date|inspection_score|        violation_id|violation_description|risk_category|\n",
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "|      97722|               94133| 97722_20181217|12/17/2018 12:00:...|              96|97722_20181217_10...| Unclean or degrad...|     Low Risk|\n",
            "|      95023|               94112| 95023_20180510|05/10/2018 12:00:...|              92|95023_20180510_10...| Wiping cloths not...|     Low Risk|\n",
            "|      94977|               94107| 94977_20180911|09/11/2018 12:00:...|              96|94977_20180911_10...| Inadequate and in...|Moderate Risk|\n",
            "|      96578|               94108| 96578_20180817|08/17/2018 12:00:...|              78|96578_20180817_10...| Inadequately clea...|Moderate Risk|\n",
            "|      94928|               94121| 94928_20190822|08/22/2019 12:00:...|              90|94928_20190822_10...| Improper or defec...|     Low Risk|\n",
            "|      95401|               94123| 95401_20180607|06/07/2018 12:00:...|              89|95401_20180607_10...| High risk food ho...|    High Risk|\n",
            "|      94710|               94117| 94710_20190617|06/17/2019 12:00:...|              70|94710_20190617_10...| Unclean or degrad...|     Low Risk|\n",
            "|      95754|               94117| 95754_20190327|03/27/2019 12:00:...|              84|95754_20190327_10...| Moderate risk ver...|Moderate Risk|\n",
            "|     100219|               94121|100219_20190618|06/18/2019 12:00:...|              91|100219_20190618_1...| High risk food ho...|    High Risk|\n",
            "|      94605|               94114| 94605_20190205|02/05/2019 12:00:...|              92|94605_20190205_10...| Unapproved or unm...|     Low Risk|\n",
            "|      96532|               94102| 96532_20190411|04/11/2019 12:00:...|              92|96532_20190411_10...| Unapproved or unm...|     Low Risk|\n",
            "|      97503|               94103| 97503_20190610|06/10/2019 12:00:...|              92|97503_20190610_10...| Inadequate and in...|Moderate Risk|\n",
            "|      96202|               94105| 96202_20190408|04/08/2019 12:00:...|              85|96202_20190408_10...| Inadequately clea...|Moderate Risk|\n",
            "|      72176|               94107| 72176_20170207|02/07/2017 12:00:...|              66|72176_20170207_10...| Improper cooling ...|    High Risk|\n",
            "|      74010|               94127| 74010_20180720|07/20/2018 12:00:...|              74|74010_20180720_10...| Improper cooling ...|    High Risk|\n",
            "|      74453|               94114| 74453_20180606|06/06/2018 12:00:...|              83|74453_20180606_10...| High risk food ho...|    High Risk|\n",
            "|      75402|               94112| 75402_20180724|07/24/2018 12:00:...|              92|75402_20180724_10...| Low risk vermin i...|     Low Risk|\n",
            "|      76465|               94103| 76465_20170530|05/30/2017 12:00:...|              94|76465_20170530_10...| Other moderate ri...|Moderate Risk|\n",
            "|      76942|               94116| 76942_20170810|08/10/2017 12:00:...|              71|76942_20170810_10...| Contaminated or a...|    High Risk|\n",
            "|      77457|               94103| 77457_20170517|05/17/2017 12:00:...|              92|77457_20170517_10...| Improper food sto...|     Low Risk|\n",
            "+-----------+--------------------+---------------+--------------------+----------------+--------------------+---------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows\n",
        "num_rows = df_drop.count()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of rows in the DataFrame: {num_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2i5SFLUpiU7",
        "outputId": "d1cbeb4b-0e61-4b5d-cefe-3e71f394069a"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the DataFrame: 36703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_drop.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpsQ-W-MYqvN",
        "outputId": "6ef4edcd-0ddf-464b-c9eb-4b02dd19878f"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: integer (nullable = true)\n",
            " |-- business_postal_code: string (nullable = true)\n",
            " |-- inspection_id: string (nullable = true)\n",
            " |-- inspection_date: string (nullable = true)\n",
            " |-- inspection_score: integer (nullable = true)\n",
            " |-- violation_id: string (nullable = true)\n",
            " |-- violation_description: string (nullable = true)\n",
            " |-- risk_category: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to deal with date as month, day, year?"
      ],
      "metadata": {
        "id": "Te97FiiVfu-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, split, to_date, date_format\n",
        "\n",
        "# Split the 'inspection_date' column by space to separate date and time, then take the date part\n",
        "df_split = df_drop.withColumn(\"date\", split(col(\"inspection_date\"), \" \").getItem(0))\n",
        "\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "df_split.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_h2WFr65HUj",
        "outputId": "2006cec5-2a03-46dd-9455-d34ac06baaf7"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+---------------+----------------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "|business_id|business_postal_code|inspection_id  |inspection_date       |inspection_score|violation_id          |violation_description                                             |risk_category|date      |\n",
            "+-----------+--------------------+---------------+----------------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "|97722      |94133               |97722_20181217 |12/17/2018 12:00:00 AM|96              |97722_20181217_103154 |Unclean or degraded floors walls or ceilings                      |Low Risk     |12/17/2018|\n",
            "|95023      |94112               |95023_20180510 |05/10/2018 12:00:00 AM|92              |95023_20180510_103149 |Wiping cloths not clean or properly stored or inadequate sanitizer|Low Risk     |05/10/2018|\n",
            "|94977      |94107               |94977_20180911 |09/11/2018 12:00:00 AM|96              |94977_20180911_103119 |Inadequate and inaccessible handwashing facilities                |Moderate Risk|09/11/2018|\n",
            "|96578      |94108               |96578_20180817 |08/17/2018 12:00:00 AM|78              |96578_20180817_103124 |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|08/17/2018|\n",
            "|94928      |94121               |94928_20190822 |08/22/2019 12:00:00 AM|90              |94928_20190822_103150 |Improper or defective plumbing                                    |Low Risk     |08/22/2019|\n",
            "|95401      |94123               |95401_20180607 |06/07/2018 12:00:00 AM|89              |95401_20180607_103103 |High risk food holding temperature                                |High Risk    |06/07/2018|\n",
            "|94710      |94117               |94710_20190617 |06/17/2019 12:00:00 AM|70              |94710_20190617_103154 |Unclean or degraded floors walls or ceilings                      |Low Risk     |06/17/2019|\n",
            "|95754      |94117               |95754_20190327 |03/27/2019 12:00:00 AM|84              |95754_20190327_103131 |Moderate risk vermin infestation                                  |Moderate Risk|03/27/2019|\n",
            "|100219     |94121               |100219_20190618|06/18/2019 12:00:00 AM|91              |100219_20190618_103103|High risk food holding temperature                                |High Risk    |06/18/2019|\n",
            "|94605      |94114               |94605_20190205 |02/05/2019 12:00:00 AM|92              |94605_20190205_103144 |Unapproved or unmaintained equipment or utensils                  |Low Risk     |02/05/2019|\n",
            "|96532      |94102               |96532_20190411 |04/11/2019 12:00:00 AM|92              |96532_20190411_103144 |Unapproved or unmaintained equipment or utensils                  |Low Risk     |04/11/2019|\n",
            "|97503      |94103               |97503_20190610 |06/10/2019 12:00:00 AM|92              |97503_20190610_103119 |Inadequate and inaccessible handwashing facilities                |Moderate Risk|06/10/2019|\n",
            "|96202      |94105               |96202_20190408 |04/08/2019 12:00:00 AM|85              |96202_20190408_103124 |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|04/08/2019|\n",
            "|72176      |94107               |72176_20170207 |02/07/2017 12:00:00 AM|66              |72176_20170207_103105 |Improper cooling methods                                          |High Risk    |02/07/2017|\n",
            "|74010      |94127               |74010_20180720 |07/20/2018 12:00:00 AM|74              |74010_20180720_103105 |Improper cooling methods                                          |High Risk    |07/20/2018|\n",
            "|74453      |94114               |74453_20180606 |06/06/2018 12:00:00 AM|83              |74453_20180606_103103 |High risk food holding temperature                                |High Risk    |06/06/2018|\n",
            "|75402      |94112               |75402_20180724 |07/24/2018 12:00:00 AM|92              |75402_20180724_103161 |Low risk vermin infestation                                       |Low Risk     |07/24/2018|\n",
            "|76465      |94103               |76465_20170530 |05/30/2017 12:00:00 AM|94              |76465_20170530_103134 |Other moderate risk violation                                     |Moderate Risk|05/30/2017|\n",
            "|76942      |94116               |76942_20170810 |08/10/2017 12:00:00 AM|71              |76942_20170810_103108 |Contaminated or adulterated food                                  |High Risk    |08/10/2017|\n",
            "|77457      |94103               |77457_20170517 |05/17/2017 12:00:00 AM|92              |77457_20170517_103139 |Improper food storage                                             |Low Risk     |05/17/2017|\n",
            "+-----------+--------------------+---------------+----------------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'inspection_date' columns\n",
        "df_split = df_split.drop(\"inspection_date\")\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "df_split.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9YNw5Nc98o1",
        "outputId": "51991fee-0383-41a3-bb76-edaa75e47e8b"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+---------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "|business_id|business_postal_code|inspection_id  |inspection_score|violation_id          |violation_description                                             |risk_category|date      |\n",
            "+-----------+--------------------+---------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "|97722      |94133               |97722_20181217 |96              |97722_20181217_103154 |Unclean or degraded floors walls or ceilings                      |Low Risk     |12/17/2018|\n",
            "|95023      |94112               |95023_20180510 |92              |95023_20180510_103149 |Wiping cloths not clean or properly stored or inadequate sanitizer|Low Risk     |05/10/2018|\n",
            "|94977      |94107               |94977_20180911 |96              |94977_20180911_103119 |Inadequate and inaccessible handwashing facilities                |Moderate Risk|09/11/2018|\n",
            "|96578      |94108               |96578_20180817 |78              |96578_20180817_103124 |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|08/17/2018|\n",
            "|94928      |94121               |94928_20190822 |90              |94928_20190822_103150 |Improper or defective plumbing                                    |Low Risk     |08/22/2019|\n",
            "|95401      |94123               |95401_20180607 |89              |95401_20180607_103103 |High risk food holding temperature                                |High Risk    |06/07/2018|\n",
            "|94710      |94117               |94710_20190617 |70              |94710_20190617_103154 |Unclean or degraded floors walls or ceilings                      |Low Risk     |06/17/2019|\n",
            "|95754      |94117               |95754_20190327 |84              |95754_20190327_103131 |Moderate risk vermin infestation                                  |Moderate Risk|03/27/2019|\n",
            "|100219     |94121               |100219_20190618|91              |100219_20190618_103103|High risk food holding temperature                                |High Risk    |06/18/2019|\n",
            "|94605      |94114               |94605_20190205 |92              |94605_20190205_103144 |Unapproved or unmaintained equipment or utensils                  |Low Risk     |02/05/2019|\n",
            "|96532      |94102               |96532_20190411 |92              |96532_20190411_103144 |Unapproved or unmaintained equipment or utensils                  |Low Risk     |04/11/2019|\n",
            "|97503      |94103               |97503_20190610 |92              |97503_20190610_103119 |Inadequate and inaccessible handwashing facilities                |Moderate Risk|06/10/2019|\n",
            "|96202      |94105               |96202_20190408 |85              |96202_20190408_103124 |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|04/08/2019|\n",
            "|72176      |94107               |72176_20170207 |66              |72176_20170207_103105 |Improper cooling methods                                          |High Risk    |02/07/2017|\n",
            "|74010      |94127               |74010_20180720 |74              |74010_20180720_103105 |Improper cooling methods                                          |High Risk    |07/20/2018|\n",
            "|74453      |94114               |74453_20180606 |83              |74453_20180606_103103 |High risk food holding temperature                                |High Risk    |06/06/2018|\n",
            "|75402      |94112               |75402_20180724 |92              |75402_20180724_103161 |Low risk vermin infestation                                       |Low Risk     |07/24/2018|\n",
            "|76465      |94103               |76465_20170530 |94              |76465_20170530_103134 |Other moderate risk violation                                     |Moderate Risk|05/30/2017|\n",
            "|76942      |94116               |76942_20170810 |71              |76942_20170810_103108 |Contaminated or adulterated food                                  |High Risk    |08/10/2017|\n",
            "|77457      |94103               |77457_20170517 |92              |77457_20170517_103139 |Improper food storage                                             |Low Risk     |05/17/2017|\n",
            "+-----------+--------------------+---------------+----------------+----------------------+------------------------------------------------------------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split, regexp_replace, col\n",
        "\n",
        "\n",
        "from pyspark.sql.types import LongType  # Ensure you import the appropriate type\n",
        "\n",
        "# Remove underscores and convert to LongType\n",
        "df_split = df_split.withColumn(\"inspection_id\", regexp_replace(col(\"inspection_id\"), \"_\", \"\"))\n",
        "\n",
        "# Show Results\n",
        "df_split.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahgxygJshJZD",
        "outputId": "56bc3387-1bb4-467e-a351-0a44336ac714"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------+----------------+--------------------+---------------------+-------------+----------+\n",
            "|business_id|business_postal_code| inspection_id|inspection_score|        violation_id|violation_description|risk_category|      date|\n",
            "+-----------+--------------------+--------------+----------------+--------------------+---------------------+-------------+----------+\n",
            "|      97722|               94133| 9772220181217|              96|97722_20181217_10...| Unclean or degrad...|     Low Risk|12/17/2018|\n",
            "|      95023|               94112| 9502320180510|              92|95023_20180510_10...| Wiping cloths not...|     Low Risk|05/10/2018|\n",
            "|      94977|               94107| 9497720180911|              96|94977_20180911_10...| Inadequate and in...|Moderate Risk|09/11/2018|\n",
            "|      96578|               94108| 9657820180817|              78|96578_20180817_10...| Inadequately clea...|Moderate Risk|08/17/2018|\n",
            "|      94928|               94121| 9492820190822|              90|94928_20190822_10...| Improper or defec...|     Low Risk|08/22/2019|\n",
            "|      95401|               94123| 9540120180607|              89|95401_20180607_10...| High risk food ho...|    High Risk|06/07/2018|\n",
            "|      94710|               94117| 9471020190617|              70|94710_20190617_10...| Unclean or degrad...|     Low Risk|06/17/2019|\n",
            "|      95754|               94117| 9575420190327|              84|95754_20190327_10...| Moderate risk ver...|Moderate Risk|03/27/2019|\n",
            "|     100219|               94121|10021920190618|              91|100219_20190618_1...| High risk food ho...|    High Risk|06/18/2019|\n",
            "|      94605|               94114| 9460520190205|              92|94605_20190205_10...| Unapproved or unm...|     Low Risk|02/05/2019|\n",
            "|      96532|               94102| 9653220190411|              92|96532_20190411_10...| Unapproved or unm...|     Low Risk|04/11/2019|\n",
            "|      97503|               94103| 9750320190610|              92|97503_20190610_10...| Inadequate and in...|Moderate Risk|06/10/2019|\n",
            "|      96202|               94105| 9620220190408|              85|96202_20190408_10...| Inadequately clea...|Moderate Risk|04/08/2019|\n",
            "|      72176|               94107| 7217620170207|              66|72176_20170207_10...| Improper cooling ...|    High Risk|02/07/2017|\n",
            "|      74010|               94127| 7401020180720|              74|74010_20180720_10...| Improper cooling ...|    High Risk|07/20/2018|\n",
            "|      74453|               94114| 7445320180606|              83|74453_20180606_10...| High risk food ho...|    High Risk|06/06/2018|\n",
            "|      75402|               94112| 7540220180724|              92|75402_20180724_10...| Low risk vermin i...|     Low Risk|07/24/2018|\n",
            "|      76465|               94103| 7646520170530|              94|76465_20170530_10...| Other moderate ri...|Moderate Risk|05/30/2017|\n",
            "|      76942|               94116| 7694220170810|              71|76942_20170810_10...| Contaminated or a...|    High Risk|08/10/2017|\n",
            "|      77457|               94103| 7745720170517|              92|77457_20170517_10...| Improper food sto...|     Low Risk|05/17/2017|\n",
            "+-----------+--------------------+--------------+----------------+--------------------+---------------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split, col, concat\n",
        "\n",
        "# Split the 'violation_id' by underscore and take the first and last parts, then concatenate them without an underscore\n",
        "df_cleaned = df_split.withColumn(\n",
        "    \"cleaned_violation_id\", (split(col(\"violation_id\"), \"_\").getItem(2))\n",
        ")\n",
        "\n",
        "# Show the results\n",
        "df_cleaned.select(\"violation_id\", \"cleaned_violation_id\", \"violation_description\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-MkBOPdG3RS",
        "outputId": "da04f6b8-60a7-4a51-fa74-98b240145ec2"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+--------------------+------------------------------------------------------------------+\n",
            "|violation_id          |cleaned_violation_id|violation_description                                             |\n",
            "+----------------------+--------------------+------------------------------------------------------------------+\n",
            "|97722_20181217_103154 |103154              |Unclean or degraded floors walls or ceilings                      |\n",
            "|95023_20180510_103149 |103149              |Wiping cloths not clean or properly stored or inadequate sanitizer|\n",
            "|94977_20180911_103119 |103119              |Inadequate and inaccessible handwashing facilities                |\n",
            "|96578_20180817_103124 |103124              |Inadequately cleaned or sanitized food contact surfaces           |\n",
            "|94928_20190822_103150 |103150              |Improper or defective plumbing                                    |\n",
            "|95401_20180607_103103 |103103              |High risk food holding temperature                                |\n",
            "|94710_20190617_103154 |103154              |Unclean or degraded floors walls or ceilings                      |\n",
            "|95754_20190327_103131 |103131              |Moderate risk vermin infestation                                  |\n",
            "|100219_20190618_103103|103103              |High risk food holding temperature                                |\n",
            "|94605_20190205_103144 |103144              |Unapproved or unmaintained equipment or utensils                  |\n",
            "|96532_20190411_103144 |103144              |Unapproved or unmaintained equipment or utensils                  |\n",
            "|97503_20190610_103119 |103119              |Inadequate and inaccessible handwashing facilities                |\n",
            "|96202_20190408_103124 |103124              |Inadequately cleaned or sanitized food contact surfaces           |\n",
            "|72176_20170207_103105 |103105              |Improper cooling methods                                          |\n",
            "|74010_20180720_103105 |103105              |Improper cooling methods                                          |\n",
            "|74453_20180606_103103 |103103              |High risk food holding temperature                                |\n",
            "|75402_20180724_103161 |103161              |Low risk vermin infestation                                       |\n",
            "|76465_20170530_103134 |103134              |Other moderate risk violation                                     |\n",
            "|76942_20170810_103108 |103108              |Contaminated or adulterated food                                  |\n",
            "|77457_20170517_103139 |103139              |Improper food storage                                             |\n",
            "+----------------------+--------------------+------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the violation_id column\n",
        "df_cleaned = df_cleaned.drop(\"violation_id\")\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "df_cleaned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eW-LejwFlb9",
        "outputId": "ae9dddb3-4390-4e61-bd95-4bbc6645d8d6"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------+----------------+------------------------------------------------------------------+-------------+----------+--------------------+\n",
            "|business_id|business_postal_code|inspection_id |inspection_score|violation_description                                             |risk_category|date      |cleaned_violation_id|\n",
            "+-----------+--------------------+--------------+----------------+------------------------------------------------------------------+-------------+----------+--------------------+\n",
            "|97722      |94133               |9772220181217 |96              |Unclean or degraded floors walls or ceilings                      |Low Risk     |12/17/2018|103154              |\n",
            "|95023      |94112               |9502320180510 |92              |Wiping cloths not clean or properly stored or inadequate sanitizer|Low Risk     |05/10/2018|103149              |\n",
            "|94977      |94107               |9497720180911 |96              |Inadequate and inaccessible handwashing facilities                |Moderate Risk|09/11/2018|103119              |\n",
            "|96578      |94108               |9657820180817 |78              |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|08/17/2018|103124              |\n",
            "|94928      |94121               |9492820190822 |90              |Improper or defective plumbing                                    |Low Risk     |08/22/2019|103150              |\n",
            "|95401      |94123               |9540120180607 |89              |High risk food holding temperature                                |High Risk    |06/07/2018|103103              |\n",
            "|94710      |94117               |9471020190617 |70              |Unclean or degraded floors walls or ceilings                      |Low Risk     |06/17/2019|103154              |\n",
            "|95754      |94117               |9575420190327 |84              |Moderate risk vermin infestation                                  |Moderate Risk|03/27/2019|103131              |\n",
            "|100219     |94121               |10021920190618|91              |High risk food holding temperature                                |High Risk    |06/18/2019|103103              |\n",
            "|94605      |94114               |9460520190205 |92              |Unapproved or unmaintained equipment or utensils                  |Low Risk     |02/05/2019|103144              |\n",
            "|96532      |94102               |9653220190411 |92              |Unapproved or unmaintained equipment or utensils                  |Low Risk     |04/11/2019|103144              |\n",
            "|97503      |94103               |9750320190610 |92              |Inadequate and inaccessible handwashing facilities                |Moderate Risk|06/10/2019|103119              |\n",
            "|96202      |94105               |9620220190408 |85              |Inadequately cleaned or sanitized food contact surfaces           |Moderate Risk|04/08/2019|103124              |\n",
            "|72176      |94107               |7217620170207 |66              |Improper cooling methods                                          |High Risk    |02/07/2017|103105              |\n",
            "|74010      |94127               |7401020180720 |74              |Improper cooling methods                                          |High Risk    |07/20/2018|103105              |\n",
            "|74453      |94114               |7445320180606 |83              |High risk food holding temperature                                |High Risk    |06/06/2018|103103              |\n",
            "|75402      |94112               |7540220180724 |92              |Low risk vermin infestation                                       |Low Risk     |07/24/2018|103161              |\n",
            "|76465      |94103               |7646520170530 |94              |Other moderate risk violation                                     |Moderate Risk|05/30/2017|103134              |\n",
            "|76942      |94116               |7694220170810 |71              |Contaminated or adulterated food                                  |High Risk    |08/10/2017|103108              |\n",
            "|77457      |94103               |7745720170517 |92              |Improper food storage                                             |Low Risk     |05/17/2017|103139              |\n",
            "+-----------+--------------------+--------------+----------------+------------------------------------------------------------------+-------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows\n",
        "num_rows = df_cleaned.count()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of rows in the DataFrame: {num_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugolIhdOch4O",
        "outputId": "2cdf6241-3537-4ff8-f9fe-240b54dbb2e5"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the DataFrame: 36703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each column to count the number of distinct values\n",
        "for column in df_cleaned.columns:\n",
        "    distinct_count = df_cleaned.select(column).distinct().count()\n",
        "    print(f\"Column '{column}' has {distinct_count} unique values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqICgVLcbVVC",
        "outputId": "b0e32cc5-d8ab-4f07-e95a-482ba42cc491"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'business_id' has 5168 unique values.\n",
            "Column 'business_postal_code' has 51 unique values.\n",
            "Column 'inspection_id' has 11666 unique values.\n",
            "Column 'inspection_score' has 47 unique values.\n",
            "Column 'violation_description' has 65 unique values.\n",
            "Column 'risk_category' has 3 unique values.\n",
            "Column 'date' has 770 unique values.\n",
            "Column 'cleaned_violation_id' has 65 unique values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIeNWlq6h6Eu",
        "outputId": "a35c53de-721e-4959-d5dc-e1fe6a061d92"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: integer (nullable = true)\n",
            " |-- business_postal_code: string (nullable = true)\n",
            " |-- inspection_id: string (nullable = true)\n",
            " |-- inspection_score: integer (nullable = true)\n",
            " |-- violation_description: string (nullable = true)\n",
            " |-- risk_category: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- cleaned_violation_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oxmHADUL5EfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, dayofweek, month, year, to_date\n",
        "\n",
        "# Convert the date string to a proper date format\n",
        "df_transformed = df_cleaned.withColumn(\"date_converted\", to_date(col(\"date\"), \"MM/dd/yyyy\"))\n",
        "\n",
        "# Extract useful features like day_of_week, month, and year\n",
        "df_transformed = df_transformed.withColumn(\"day_of_week\", dayofweek(col(\"date_converted\"))) \\\n",
        "                               .withColumn(\"month\", month(col(\"date_converted\"))) \\\n",
        "                               .withColumn(\"year\", year(col(\"date_converted\")))\n",
        "\n",
        "# Optionally, you can also convert the date to an integer format in yyyyMMdd form\n",
        "df_transformed = df_transformed.withColumn(\"date_int\",\n",
        "                                           (col(\"year\") * 10000 + col(\"month\") * 100 + col(\"day_of_week\")).cast(\"int\"))\n",
        "\n",
        "# Business ID - Drop or use Label Encoding\n",
        "indexer_business = StringIndexer(inputCol=\"business_id\", outputCol=\"business_id_indexed\")\n",
        "\n",
        "# Business Postal Code - One-Hot Encoding or Label Encoding\n",
        "indexer_postal_code = StringIndexer(inputCol=\"business_postal_code\", outputCol=\"postal_code_indexed\")\n",
        "\n",
        "# Inspection ID - Drop the column (no predictive power)\n",
        "df_transformed = df_transformed.drop(\"inspection_id\")\n",
        "\n",
        "# Inspection Score - Already numeric, cast to float\n",
        "df_transformed = df_transformed.withColumn(\"inspection_score\", df_transformed[\"inspection_score\"].cast(\"float\"))\n",
        "\n",
        "# Inspection Type - Drop as only one value\n",
        "df_transformed = df_transformed.drop(\"inspection_type\")\n",
        "\n",
        "# Cleaned Violation ID - Label Encoding or One-Hot Encoding\n",
        "indexer_violation = StringIndexer(inputCol=\"cleaned_violation_id\", outputCol=\"violation_id_indexed\")\n",
        "\n",
        "# Violation Description - Use TF-IDF or CountVectorizer\n",
        "tokenizer = Tokenizer(inputCol=\"violation_description\", outputCol=\"words\")\n",
        "hashing_tf = HashingTF(inputCol=\"words\", outputCol=\"raw_features\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "\n",
        "# Risk Category - Label Encoding (Ordinal Encoding)\n",
        "indexer_risk = StringIndexer(inputCol=\"risk_category\", outputCol=\"risk_category_indexed\")\n",
        "\n",
        "# Create a Pipeline for Feature Transformation\n",
        "pipeline = Pipeline(stages=[\n",
        "    indexer_business,\n",
        "    indexer_postal_code,\n",
        "    indexer_violation,\n",
        "    indexer_risk,\n",
        "    tokenizer,\n",
        "    hashing_tf,\n",
        "    idf\n",
        "])\n",
        "\n",
        "# Fit and transform the pipeline\n",
        "df_transformed = pipeline.fit(df_transformed).transform(df_transformed)\n",
        "\n",
        "# Show the final transformed DataFrame, including the features and the new extracted columns\n",
        "df_transformed.select(\"business_id_indexed\", \"postal_code_indexed\", \"violation_id_indexed\",\n",
        "                      \"features\", \"risk_category_indexed\", \"day_of_week\", \"month\", \"inspection_score\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4sl_15TocGx",
        "outputId": "3c269fa0-c9ca-40c7-b3c2-4d049d64df39"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----+----------------+\n",
            "|business_id_indexed|postal_code_indexed|violation_id_indexed|features                                                                                                                                                                                                                   |risk_category_indexed|day_of_week|month|inspection_score|\n",
            "+-------------------+-------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----+----------------+\n",
            "|4702.0             |4.0                |0.0                 |(10000,[2690,2958,3831,5741,9827,9962],[2.4554832881094186,1.746119110410295,2.4554832881094186,1.2022433903225005,2.4554832881094186,2.4554832881094186])                                                                 |0.0                  |2          |12   |96.0            |\n",
            "|3589.0             |7.0                |5.0                 |(10000,[495,593,3061,3644,4016,5411,5741,7310,7405],[2.9947519347139715,2.996931772089392,2.996931772089392,2.996931772089392,2.996931772089392,2.996931772089392,1.2022433903225005,1.7338566362276044,1.897228970772317])|0.0                  |5          |5    |92.0            |\n",
            "|5075.0             |6.0                |3.0                 |(10000,[388,2891,3553,7310,8444],[2.685395728497323,2.683001473562675,2.685395728497323,1.7338566362276044,2.501610334859367])                                                                                             |1.0                  |3          |9    |96.0            |\n",
            "|2304.0             |9.0                |2.0                 |(10000,[1940,2450,5026,5741,8653,9027,9545],[2.6427695295327758,2.6427695295327758,2.6427695295327758,0.6011216951612502,1.1549889167928604,1.9769841024821948,1.9769841024821948])                                        |1.0                  |6          |8    |78.0            |\n",
            "|1371.0             |11.0               |20.0                |(10000,[3828,5741,7638,9339],[3.939758057589513,0.6011216951612502,1.785945973188607,3.939758057589513])                                                                                                                   |0.0                  |5          |8    |90.0            |\n",
            "|4150.0             |17.0               |9.0                 |(10000,[2116,6567,7191,8653,8794],[2.8189841971185507,2.2615887457578054,2.230690304206571,1.1549889167928604,1.5940007927302584])                                                                                         |2.0                  |5          |6    |89.0            |\n",
            "|244.0              |16.0               |0.0                 |(10000,[2690,2958,3831,5741,9827,9962],[2.4554832881094186,1.746119110410295,2.4554832881094186,1.2022433903225005,2.4554832881094186,2.4554832881094186])                                                                 |0.0                  |2          |6    |70.0            |\n",
            "|3115.0             |16.0               |7.0                 |(10000,[3898,5080,6563,8794],[2.383531834582722,2.2068886043656843,2.383531834582722,1.5940007927302584])                                                                                                                  |1.0                  |4          |3    |84.0            |\n",
            "|4222.0             |11.0               |9.0                 |(10000,[2116,6567,7191,8653,8794],[2.8189841971185507,2.2615887457578054,2.230690304206571,1.1549889167928604,1.5940007927302584])                                                                                         |2.0                  |3          |6    |91.0            |\n",
            "|3100.0             |14.0               |1.0                 |(10000,[1523,2970,5741,8730,9991],[2.2485981759621563,2.3348120112145003,1.2022433903225005,2.598950499220759,2.5527636614392843])                                                                                         |0.0                  |3          |2    |92.0            |\n",
            "|4160.0             |3.0                |1.0                 |(10000,[1523,2970,5741,8730,9991],[2.2485981759621563,2.3348120112145003,1.2022433903225005,2.598950499220759,2.5527636614392843])                                                                                         |0.0                  |5          |4    |92.0            |\n",
            "|4175.0             |1.0                |3.0                 |(10000,[388,2891,3553,7310,8444],[2.685395728497323,2.683001473562675,2.685395728497323,1.7338566362276044,2.501610334859367])                                                                                             |1.0                  |2          |6    |92.0            |\n",
            "|3118.0             |10.0               |2.0                 |(10000,[1940,2450,5026,5741,8653,9027,9545],[2.6427695295327758,2.6427695295327758,2.6427695295327758,0.6011216951612502,1.1549889167928604,1.9769841024821948,1.9769841024821948])                                        |1.0                  |2          |4    |85.0            |\n",
            "|1520.0             |6.0                |16.0                |(10000,[1834,4996,7638],[3.175659141057283,3.7844076175703507,1.785945973188607])                                                                                                                                          |2.0                  |3          |2    |66.0            |\n",
            "|1281.0             |22.0               |16.0                |(10000,[1834,4996,7638],[3.175659141057283,3.7844076175703507,1.785945973188607])                                                                                                                                          |2.0                  |6          |7    |74.0            |\n",
            "|875.0              |14.0               |9.0                 |(10000,[2116,6567,7191,8653,8794],[2.8189841971185507,2.2615887457578054,2.230690304206571,1.1549889167928604,1.5940007927302584])                                                                                         |2.0                  |4          |6    |83.0            |\n",
            "|105.0              |7.0                |12.0                |(10000,[3898,6563,8411,8794],[2.383531834582722,2.383531834582722,3.3974989112220095,1.5940007927302584])                                                                                                                  |0.0                  |3          |7    |92.0            |\n",
            "|1290.0             |1.0                |42.0                |(10000,[5080,5133,8289,8794],[2.2068886043656843,3.3529055356791906,4.997212273764115,1.5940007927302584])                                                                                                                 |1.0                  |3          |5    |94.0            |\n",
            "|1851.0             |21.0               |35.0                |(10000,[3921,5741,7191,8653],[2.9335190890524183,0.6011216951612502,2.230690304206571,1.1549889167928604])                                                                                                                 |2.0                  |5          |8    |71.0            |\n",
            "|2963.0             |1.0                |8.0                 |(10000,[3636,7638,8653],[2.4818598574419504,1.785945973188607,1.1549889167928604])                                                                                                                                         |0.0                  |4          |5    |92.0            |\n",
            "+-------------------+-------------------+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------+-----+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdOUMsabZ35J",
        "outputId": "23f40021-666a-49bd-9cbf-f714f66b5643"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: integer (nullable = true)\n",
            " |-- business_postal_code: string (nullable = true)\n",
            " |-- inspection_score: float (nullable = true)\n",
            " |-- violation_description: string (nullable = true)\n",
            " |-- risk_category: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- cleaned_violation_id: string (nullable = true)\n",
            " |-- date_converted: date (nullable = true)\n",
            " |-- day_of_week: integer (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- date_int: integer (nullable = true)\n",
            " |-- business_id_indexed: double (nullable = false)\n",
            " |-- postal_code_indexed: double (nullable = false)\n",
            " |-- violation_id_indexed: double (nullable = false)\n",
            " |-- risk_category_indexed: double (nullable = false)\n",
            " |-- words: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- raw_features: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.write.csv(\"/content/data_cleaned(2).csv\", header=True, mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "xhp9gNvXSium"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/cleaned_restaurant_inspections_single.zip /content/cleaned_restaurant_inspections_single\n",
        "from google.colab import files\n",
        "files.download('/content/cleaned_restaurant_inspections_single.zip')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "VLfZCioTuA1-",
        "outputId": "1300aaea-2215-4026-c97d-6eac04b7d756"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/cleaned_restaurant_inspections_single\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/cleaned_restaurant_inspections_single.zip . -i /content/cleaned_restaurant_inspections_single)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/cleaned_restaurant_inspections_single.zip",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-183-92d1e94679c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r /content/cleaned_restaurant_inspections_single.zip /content/cleaned_restaurant_inspections_single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/cleaned_restaurant_inspections_single.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/cleaned_restaurant_inspections_single.zip"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed.write.csv(\"/content/data_transformed.csv\", header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xu-Aw9PFpDqb",
        "outputId": "85718946-5b56-4b98-ab40-52119fd98ab3"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The CSV datasource doesn't support the column `words` of the type \"ARRAY<STRING>\".",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-ab54a07a7bcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_transformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data_transformed.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.5.5-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mlineSep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineSep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m         )\n\u001b[0;32m-> 1864\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     def orc(\n",
            "\u001b[0;32m/content/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The CSV datasource doesn't support the column `words` of the type \"ARRAY<STRING>\"."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Spark DataFrame to Pandas\n",
        "pd_transformed_df = df_transformed.toPandas()\n",
        "\n",
        "pd_transformed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "3A6vI9zTzmpi",
        "outputId": "9447f33b-85c0-4292-ddbb-db879a6f0f0d"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   business_id business_postal_code  inspection_score  \\\n",
              "0        97722                94133              96.0   \n",
              "1        95023                94112              92.0   \n",
              "2        94977                94107              96.0   \n",
              "3        96578                94108              78.0   \n",
              "4        94928                94121              90.0   \n",
              "\n",
              "                               violation_description  risk_category  \\\n",
              "0       Unclean or degraded floors walls or ceilings       Low Risk   \n",
              "1  Wiping cloths not clean or properly stored or ...       Low Risk   \n",
              "2  Inadequate and inaccessible handwashing facili...  Moderate Risk   \n",
              "3  Inadequately cleaned or sanitized food contact...  Moderate Risk   \n",
              "4                     Improper or defective plumbing       Low Risk   \n",
              "\n",
              "         date cleaned_violation_id date_converted  day_of_week  month  year  \\\n",
              "0  12/17/2018               103154     2018-12-17            2     12  2018   \n",
              "1  05/10/2018               103149     2018-05-10            5      5  2018   \n",
              "2  09/11/2018               103119     2018-09-11            3      9  2018   \n",
              "3  08/17/2018               103124     2018-08-17            6      8  2018   \n",
              "4  08/22/2019               103150     2019-08-22            5      8  2019   \n",
              "\n",
              "   date_int  business_id_indexed  postal_code_indexed  violation_id_indexed  \\\n",
              "0  20181202               4702.0                  4.0                   0.0   \n",
              "1  20180505               3589.0                  7.0                   5.0   \n",
              "2  20180903               5075.0                  6.0                   3.0   \n",
              "3  20180806               2304.0                  9.0                   2.0   \n",
              "4  20190805               1371.0                 11.0                  20.0   \n",
              "\n",
              "   risk_category_indexed                                              words  \\\n",
              "0                    0.0  [unclean, or, degraded, floors, walls, or, cei...   \n",
              "1                    0.0  [wiping, cloths, not, clean, or, properly, sto...   \n",
              "2                    1.0  [inadequate, and, inaccessible, handwashing, f...   \n",
              "3                    1.0  [inadequately, cleaned, or, sanitized, food, c...   \n",
              "4                    0.0                [improper, or, defective, plumbing]   \n",
              "\n",
              "                                        raw_features  \\\n",
              "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                            features  \n",
              "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150918fe-c184-4790-a0cb-3e1b0688764e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>business_postal_code</th>\n",
              "      <th>inspection_score</th>\n",
              "      <th>violation_description</th>\n",
              "      <th>risk_category</th>\n",
              "      <th>date</th>\n",
              "      <th>cleaned_violation_id</th>\n",
              "      <th>date_converted</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>date_int</th>\n",
              "      <th>business_id_indexed</th>\n",
              "      <th>postal_code_indexed</th>\n",
              "      <th>violation_id_indexed</th>\n",
              "      <th>risk_category_indexed</th>\n",
              "      <th>words</th>\n",
              "      <th>raw_features</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97722</td>\n",
              "      <td>94133</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Unclean or degraded floors walls or ceilings</td>\n",
              "      <td>Low Risk</td>\n",
              "      <td>12/17/2018</td>\n",
              "      <td>103154</td>\n",
              "      <td>2018-12-17</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2018</td>\n",
              "      <td>20181202</td>\n",
              "      <td>4702.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[unclean, or, degraded, floors, walls, or, cei...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95023</td>\n",
              "      <td>94112</td>\n",
              "      <td>92.0</td>\n",
              "      <td>Wiping cloths not clean or properly stored or ...</td>\n",
              "      <td>Low Risk</td>\n",
              "      <td>05/10/2018</td>\n",
              "      <td>103149</td>\n",
              "      <td>2018-05-10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2018</td>\n",
              "      <td>20180505</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[wiping, cloths, not, clean, or, properly, sto...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94977</td>\n",
              "      <td>94107</td>\n",
              "      <td>96.0</td>\n",
              "      <td>Inadequate and inaccessible handwashing facili...</td>\n",
              "      <td>Moderate Risk</td>\n",
              "      <td>09/11/2018</td>\n",
              "      <td>103119</td>\n",
              "      <td>2018-09-11</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2018</td>\n",
              "      <td>20180903</td>\n",
              "      <td>5075.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[inadequate, and, inaccessible, handwashing, f...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96578</td>\n",
              "      <td>94108</td>\n",
              "      <td>78.0</td>\n",
              "      <td>Inadequately cleaned or sanitized food contact...</td>\n",
              "      <td>Moderate Risk</td>\n",
              "      <td>08/17/2018</td>\n",
              "      <td>103124</td>\n",
              "      <td>2018-08-17</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>2018</td>\n",
              "      <td>20180806</td>\n",
              "      <td>2304.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[inadequately, cleaned, or, sanitized, food, c...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94928</td>\n",
              "      <td>94121</td>\n",
              "      <td>90.0</td>\n",
              "      <td>Improper or defective plumbing</td>\n",
              "      <td>Low Risk</td>\n",
              "      <td>08/22/2019</td>\n",
              "      <td>103150</td>\n",
              "      <td>2019-08-22</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>2019</td>\n",
              "      <td>20190805</td>\n",
              "      <td>1371.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[improper, or, defective, plumbing]</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150918fe-c184-4790-a0cb-3e1b0688764e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-150918fe-c184-4790-a0cb-3e1b0688764e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-150918fe-c184-4790-a0cb-3e1b0688764e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77c14cdd-1d8f-4e4c-a989-5983e6237176\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77c14cdd-1d8f-4e4c-a989-5983e6237176')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77c14cdd-1d8f-4e4c-a989-5983e6237176 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pd_transformed_df",
              "summary": "{\n  \"name\": \"pd_transformed_df\",\n  \"rows\": 36703,\n  \"fields\": [\n    {\n      \"column\": \"business_id\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5168,\n        \"samples\": [\n          1768,\n          88063,\n          68394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"business_postal_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 51,\n        \"samples\": [\n          \"94122-1909\",\n          \"94143\",\n          \"94301\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inspection_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          72.0,\n          63.0,\n          80.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"Reservice of previously served foods\",\n          \"Mobile food facility with unapproved operating conditions\",\n          \"Unclean or degraded floors walls or ceilings\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low Risk\",\n          \"Moderate Risk\",\n          \"High Risk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 770,\n        \"samples\": [\n          \"01/15/2019\",\n          \"11/23/2016\",\n          \"06/14/2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_violation_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"103122\",\n          \"103172\",\n          \"103154\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_converted\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-10-04\",\n        \"max\": \"2019-10-03\",\n        \"num_unique_values\": 770,\n        \"samples\": [\n          \"2019-01-15\",\n          \"2016-11-23\",\n          \"2017-06-14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1,\n          10,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2019,\n          2016,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_int\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          20180703,\n          20190203,\n          20190605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"business_id_indexed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1271.181288118233,\n        \"min\": 0.0,\n        \"max\": 5167.0,\n        \"num_unique_values\": 5168,\n        \"samples\": [\n          2001.0,\n          318.0,\n          1504.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"postal_code_indexed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.594816176678377,\n        \"min\": 0.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          49.0,\n          27.0,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_id_indexed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.628951975414006,\n        \"min\": 0.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          57.0,\n          56.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_category_indexed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.711812987995226,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_features\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"(10000,[911,4495,5956,8592,9170],[1.0,1.0,1.0,1.0,1.0])\",\n          \"(10000,[5394,7229,7650,7678,8083,8653,8730],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\",\n          \"(10000,[2690,2958,3831,5741,9827,9962],[1.0,1.0,1.0,2.0,1.0,1.0])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"(10000,[911,4495,5956,8592,9170],[8.564730870873785,2.4391101263724373,8.564730870873785,2.9887817677274677,8.564730870873785])\",\n          \"(10000,[5394,7229,7650,7678,8083,8653,8730],[6.899723107284872,5.386677040525838,4.823665663589278,8.313416442592878,7.109443638266942,1.1549889167928604,2.598950499220759])\",\n          \"(10000,[2690,2958,3831,5741,9827,9962],[2.4554832881094186,1.746119110410295,2.4554832881094186,1.2022433903225005,2.4554832881094186,2.4554832881094186])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_transformed_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmbr4Bkc1ICi",
        "outputId": "40bdaded-f5dc-4a07-dced-b9eff8f2f1f8"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 36703 entries, 0 to 36702\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   business_id            36703 non-null  int32  \n",
            " 1   business_postal_code   36703 non-null  object \n",
            " 2   inspection_score       36703 non-null  float32\n",
            " 3   violation_description  36703 non-null  object \n",
            " 4   risk_category          36703 non-null  object \n",
            " 5   date                   36703 non-null  object \n",
            " 6   cleaned_violation_id   36703 non-null  object \n",
            " 7   date_converted         36703 non-null  object \n",
            " 8   day_of_week            36703 non-null  int32  \n",
            " 9   month                  36703 non-null  int32  \n",
            " 10  year                   36703 non-null  int32  \n",
            " 11  date_int               36703 non-null  int32  \n",
            " 12  business_id_indexed    36703 non-null  float64\n",
            " 13  postal_code_indexed    36703 non-null  float64\n",
            " 14  violation_id_indexed   36703 non-null  float64\n",
            " 15  risk_category_indexed  36703 non-null  float64\n",
            " 16  words                  36703 non-null  object \n",
            " 17  raw_features           36703 non-null  object \n",
            " 18  features               36703 non-null  object \n",
            "dtypes: float32(1), float64(4), int32(5), object(9)\n",
            "memory usage: 4.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.sql.functions import col, to_date, to_timestamp, isnotnull\n",
        "\n",
        "# # Initialize Spark Session\n",
        "# spark = SparkSession.builder.appName(\"ChangeColumnTypes\").getOrCreate()\n",
        "\n",
        "# # Set legacy time parser policy\n",
        "# spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
        "\n",
        "# # Convert Spark DataFrame back to Pandas DataFrame if needed\n",
        "# # pandas_df = df_cleaned.toPandas()\n",
        "\n",
        "# # Create a Spark DataFrame from the Pandas DataFrame\n",
        "# spark_df = spark.createDataFrame(pandas_df)\n",
        "\n",
        "# # Now apply withColumn to the Spark DataFrame (spark_df)\n",
        "# df_cleaned = spark_df.withColumn(\"business_id\", col(\"business_id\").cast(\"int\")) \\\n",
        "#                .withColumn(\"inspection_id\", col(\"inspection_id\").cast(\"int\")) \\\n",
        "#                .withColumn(\"inspection_score\", col(\"inspection_score\").cast(\"int\")) \\\n",
        "#                .withColumn(\"violation_id\", col(\"violation_id\").cast(\"int\")) \\\n",
        "#                .withColumn(\"business_postal_code\", col(\"business_postal_code\").cast(\"int\")) \\\n",
        "#                .withColumn(\"inspection_date\", to_date(col(\"inspection_date\"), \"MM/dd/yyyy hh:mm:ss a\")) \\\n",
        "#                .withColumn(\"date\", to_date(col(\"date\"), \"MM/dd/yyyy\")) \\\n",
        "#                .withColumn(\"time\", to_timestamp(col(\"time\"), \"HH:mm:ss\"))  # Convert time to timestamp\n",
        "\n",
        "# # Show Schema After Conversion\n",
        "# df_cleaned.printSchema()"
      ],
      "metadata": {
        "id": "_w4bJt-QgQW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# # Drop unnecessary columns\n",
        "# columns_to_drop = ['business_name', 'business_address', 'inspection_type']\n",
        "# # 'date' and 'time' are dropped here\n",
        "# df = pandas_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# # Handle categorical variables\n",
        "# categorical_cols = df.select_dtypes(include='object').columns\n",
        "# df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# # Check\n",
        "# df_encoded.head()"
      ],
      "metadata": {
        "id": "TDURei361Pkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REGRESSION**"
      ],
      "metadata": {
        "id": "X7xyUUu1LhkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "# from sklearn.svm import SVR, SVC\n",
        "# from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# # 6. Features & Target for Regression\n",
        "# X_reg = df_encoded.drop('inspection_score', axis=1)\n",
        "# y_reg = df_encoded['inspection_score']\n",
        "\n",
        "# # Convert datetime columns to numerical representation (e.g., Unix timestamp)\n",
        "# for col in X_reg.select_dtypes(include=['datetime64']).columns:\n",
        "#     X_reg[col] = X_reg[col].astype(np.int64) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# # 7. Train-Test Split\n",
        "# X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# # 8. Apply StandardScaler (only for Linear Regression and SVM)\n",
        "# scaler = StandardScaler()\n",
        "# X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
        "# X_test_reg_scaled = scaler.transform(X_test_reg)\n",
        "\n",
        "# # 9. Train Models\n",
        "# # Linear Regression (Scaled)\n",
        "# lr = LinearRegression()\n",
        "# lr.fit(X_train_reg_scaled, y_train_reg)\n",
        "# y_pred_lr = lr.predict(X_test_reg_scaled)\n",
        "\n",
        "# # Random Forest Regressor (No Scaling Needed)\n",
        "# rf_reg = RandomForestRegressor()\n",
        "# rf_reg.fit(X_train_reg, y_train_reg)\n",
        "# y_pred_rf = rf_reg.predict(X_test_reg)\n",
        "\n",
        "# # SVR (Scaled)\n",
        "# svr = SVR()\n",
        "# svr.fit(X_train_reg_scaled, y_train_reg)\n",
        "# y_pred_svr = svr.predict(X_test_reg_scaled)\n",
        "\n",
        "# # 10. Evaluate Regression Models\n",
        "# rmse_lr = mean_squared_error(y_test_reg, y_pred_lr) ** 0.5  # Calculate RMSE manually\n",
        "# rmse_rf = mean_squared_error(y_test_reg, y_pred_rf) ** 0.5  # Calculate RMSE manually\n",
        "# rmse_svr = mean_squared_error(y_test_reg, y_pred_svr) ** 0.5  # Calculate RMSE manually\n",
        "\n",
        "\n",
        "# print(f\"Linear Regression RMSE: {rmse_lr}\")\n",
        "# print(f\"Random Forest Regressor RMSE: {rmse_rf}\")\n",
        "# print(f\"SVR RMSE: {rmse_svr}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "V-apiaEv2dG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Encode categorical features\n",
        "# Label encode columns with few categories (e.g., 'risk_category')\n",
        "label_encoder = LabelEncoder()\n",
        "pd_transformed_df['risk_category_encoded'] = label_encoder.fit_transform(pd_transformed_df['risk_category'])\n",
        "\n",
        "# One-Hot encode columns with many categories (e.g., 'business_postal_code', 'violation_description')\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=['business_postal_code', 'violation_description'], drop_first=True)\n",
        "\n",
        "# Step 2: Handle date columns (if needed)\n",
        "# You can either drop the 'date' or 'date_converted' columns or extract time features:\n",
        "df_encoded['date_converted'] = pd.to_datetime(df_encoded['date_converted'])\n",
        "df_encoded['year'] = df_encoded['date_converted'].dt.year\n",
        "df_encoded['month'] = df_encoded['date_converted'].dt.month\n",
        "df_encoded['day'] = df_encoded['date_converted'].dt.day\n",
        "df_encoded.drop(['date_converted', 'date'], axis=1, inplace=True)\n",
        "\n",
        "# Step 3: Separate features and target\n",
        "X = df_encoded.drop(['inspection_score'], axis=1)\n",
        "y = df_encoded['inspection_score']\n",
        "\n",
        "# Step 4: Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Apply scaling to numerical columns\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=[np.number]))\n",
        "X_test_scaled = scaler.transform(X_test.select_dtypes(include=[np.number]))\n",
        "\n",
        "# Step 6: Train models (example with Linear Regression)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse_lr = mean_squared_error(y_test, y_pred_lr) ** 0.5\n",
        "print(f\"Linear Regression RMSE: {rmse_lr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRekMOG5rx-E",
        "outputId": "9ea90f50-3090-459e-eb66-c2440859f123"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression RMSE: 6.36326362709294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 6. Features & Target for Regression\n",
        "X_reg = df_encoded.drop('inspection_score', axis=1)\n",
        "y_reg = df_encoded['inspection_score']\n",
        "\n",
        "# Convert datetime columns to numerical representation (e.g., Unix timestamp)\n",
        "for col in X_reg.select_dtypes(include=['datetime64']).columns:\n",
        "    X_reg[col] = X_reg[col].astype(np.int64) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# 7. Train-Test Split\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# 8. Apply StandardScaler (only for Linear Regression and SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
        "\n",
        "# 9. Train Models\n",
        "# Linear Regression (Scaled)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_reg_scaled, y_train_reg)\n",
        "y_pred_lr = lr.predict(X_test_reg_scaled)\n",
        "\n",
        "# Random Forest Regressor (No Scaling Needed)\n",
        "rf_reg = RandomForestRegressor()\n",
        "rf_reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_rf = rf_reg.predict(X_test_reg)\n",
        "\n",
        "# SVR (Scaled)\n",
        "svr = SVR()\n",
        "svr.fit(X_train_reg_scaled, y_train_reg)\n",
        "y_pred_svr = svr.predict(X_test_reg_scaled)\n",
        "\n",
        "# 10. Evaluate Regression Models\n",
        "rmse_lr = mean_squared_error(y_test_reg, y_pred_lr) ** 0.5  # Calculate RMSE manually\n",
        "rmse_rf = mean_squared_error(y_test_reg, y_pred_rf) ** 0.5  # Calculate RMSE manually\n",
        "rmse_svr = mean_squared_error(y_test_reg, y_pred_svr) ** 0.5  # Calculate RMSE manually\n",
        "\n",
        "\n",
        "print(f\"Linear Regression RMSE: {rmse_lr}\")\n",
        "print(f\"Random Forest Regressor RMSE: {rmse_rf}\")\n",
        "print(f\"SVR RMSE: {rmse_svr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "oee-6rPWqRmc",
        "outputId": "ab35918b-2193-4326-96da-2a416b23f2bb"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Moderate Risk'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-d634f7aee2f8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 8. Apply StandardScaler (only for Linear Regression and SVM)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX_train_reg_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mX_test_reg_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;31m# Use the original dtype for conversion if dtype is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mnew_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m         \u001b[0;31m# Since we converted here, we do not need to convert again later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6641\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6642\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6643\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6644\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Moderate Risk'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Line Chart: Regression Model Comparison\n",
        "model_names_reg = ['Linear Regression', 'Random Forest', 'SVR']\n",
        "rmse_scores = [rmse_lr, rmse_rf, rmse_svr]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(model_names_reg, rmse_scores, marker='o', color='purple')\n",
        "plt.title('Regression Models RMSE Comparison')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('RMSE')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1Y0-AEZHL8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Report: Regression Models RMSE Analysis\")\n",
        "print(\"The Random Forest Regressor has the lowest RMSE, meaning it's the best model for predicting inspection scores. The SVR model performs the worst, confirming that tree-based methods work better for this dataset.\")\n"
      ],
      "metadata": {
        "id": "QrNj9puwHVN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASSIFICATION**"
      ],
      "metadata": {
        "id": "LMIMXv8vLo4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Features & Target for Classification\n",
        "target_col = [col for col in df_encoded.columns if 'risk_category' in col][0]\n",
        "X_clf = df_encoded.drop(target_col, axis=1)\n",
        "y_clf = df_encoded[target_col]\n",
        "\n",
        "# Convert datetime columns to numerical representation (e.g., Unix timestamp)\n",
        "for col in X_clf.select_dtypes(include=['datetime64']).columns:\n",
        "    X_clf[col] = X_clf[col].astype(np.int64) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "\n",
        "# 13. Train-Test Split\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n",
        "\n",
        "# 14. Apply StandardScaler (only for Logistic Regression and SVM)\n",
        "X_train_clf_scaled = scaler.fit_transform(X_train_clf)\n",
        "X_test_clf_scaled = scaler.transform(X_test_clf)\n",
        "\n",
        "# 15. Train Classification Models\n",
        "# Logistic Regression (Scaled)\n",
        "logr = LogisticRegression(max_iter=1000)\n",
        "logr.fit(X_train_clf_scaled, y_train_clf)\n",
        "y_pred_logr = logr.predict(X_test_clf_scaled)\n",
        "\n",
        "# Random Forest Classifier (No Scaling Needed)\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train_clf, y_train_clf)\n",
        "y_pred_rfc = rfc.predict(X_test_clf)\n",
        "\n",
        "# SVM Classifier (Scaled)\n",
        "svc = SVC()\n",
        "svc.fit(X_train_clf_scaled, y_train_clf)\n",
        "y_pred_svc = svc.predict(X_test_clf_scaled)\n",
        "\n",
        "# 16. Evaluate Classification Models\n",
        "acc_logr = accuracy_score(y_test_clf, y_pred_logr)\n",
        "acc_rfc = accuracy_score(y_test_clf, y_pred_rfc)\n",
        "acc_svc = accuracy_score(y_test_clf, y_pred_svc)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {acc_logr}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {acc_rfc}\")\n",
        "print(f\"SVM Classifier Accuracy: {acc_svc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ct2w6OdvHj1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Line Chart: Classification Accuracy Comparison\n",
        "model_names_clf = ['Logistic Regression', 'Random Forest', 'SVM']\n",
        "accuracy_scores = [acc_logr, acc_rfc, acc_svc]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(model_names_clf, accuracy_scores, marker='s', linestyle='-', color='green')\n",
        "plt.title('Classification Models Accuracy Comparison')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HTKgc5T1HwBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Report: Classification Models Accuracy Analysis\")\n",
        "print(\"Random Forest Classifier achieves the highest accuracy, proving it's the best model for risk classification. Logistic Regression performs decently, while SVM has slightly lower accuracy.\")\n"
      ],
      "metadata": {
        "id": "tWQNJM3vH4qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming risk_category column exists\n",
        "# Check column names first\n",
        "print(pandas_df.columns)\n",
        "\n",
        "# Let's say column name is 'risk_category_Low' or similar after encoding\n",
        "target_col = [col for col in df_encoded.columns if 'risk_category' in col][0]\n",
        "\n",
        "# Features and Target\n",
        "X_class = df_encoded.drop(target_col, axis=1)\n",
        "y_class = df_encoded[target_col]\n",
        "\n",
        "# Convert datetime columns to numerical representation (e.g., Unix timestamp)\n",
        "for col in X_class.select_dtypes(include=['datetime64']).columns:\n",
        "    X_class[col] = X_class[col].astype(np.int64) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply StandardScaler (only for Logistic Regression and SVM)\n",
        "scaler = StandardScaler() # Initialize StandardScaler\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "logr = LogisticRegression(max_iter=1000)\n",
        "logr.fit(X_train_scaled, y_train)  # Use scaled data for Logistic Regression\n",
        "y_pred_logr = logr.predict(X_test_scaled)  # Use scaled data for prediction\n",
        "\n",
        "# Random Forest Classifier\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred_rfc = rfc.predict(X_test)\n",
        "\n",
        "# SVM Classifier\n",
        "svc = SVC()\n",
        "svc.fit(X_train_scaled, y_train)  # Use scaled data for SVM\n",
        "y_pred_svc = svc.predict(X_test_scaled)  # Use scaled data for prediction\n",
        "\n",
        "# Evaluation\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logr))\n",
        "print(confusion_matrix(y_test, y_pred_logr))\n",
        "print(classification_report(y_test, y_pred_logr))\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rfc))\n",
        "print(confusion_matrix(y_test, y_pred_rfc))\n",
        "print(classification_report(y_test, y_pred_rfc))\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(confusion_matrix(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc))"
      ],
      "metadata": {
        "id": "7X8y6wOC3uYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix (Classification Results)**"
      ],
      "metadata": {
        "id": "g-aVmcWaXEq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# For Random Forest Classifier\n",
        "ConfusionMatrixDisplay.from_estimator(rfc, X_test, y_test, cmap='Blues')\n",
        "plt.title('Random Forest Classifier - Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Similarly, for Logistic Regression:\n",
        "ConfusionMatrixDisplay.from_estimator(logr, X_test, y_test, cmap='Greens')\n",
        "plt.title('Logistic Regression - Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ezAZ1swJUezB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The confusion matrix **for the Random Forest Classifier shows the number of correct and incorrect predictions for each risk category.\n",
        "The diagonal values (top-left to bottom-right) indicate correct classifications (True Positives and True Negatives).\n",
        "The off-diagonal values indicate misclassifications where the model predicted the wrong category.\n",
        "If most values are concentrated along the diagonal, it means the model is performing well.\n",
        "\n",
        "**The confusion matrix for Logistic Regression** follows the same structure as above.\n",
        "Since Logistic Regression is a linear model, it may perform worse if the data is not linearly separable.\n",
        "If Logistic Regression's confusion matrix has more misclassifications (compared to Random Forest), it indicates that the problem is likely non-linear, and tree-based models (like Random Forest) are a better fit."
      ],
      "metadata": {
        "id": "p1dXxiR8WaS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature vs. Target (Trend Lines)**"
      ],
      "metadata": {
        "id": "ty2WA-0UA_m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot using business_id (or another existing column) instead of inspection_id\n",
        "plt.figure(figsize=(10, 5))\n",
        "# Assuming 'inspection_score' is present in pandas_df\n",
        "plt.scatter(pandas_df['business_id'], pandas_df['inspection_score'], marker='o', linestyle='-')\n",
        "plt.title('Inspection Scores Across Different Businesses')\n",
        "plt.xlabel('Business ID')\n",
        "plt.ylabel('Inspection Score')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_3YfiN-B74q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression: Actual vs Predicted Plot**"
      ],
      "metadata": {
        "id": "6Lxdh3SQBbxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_rf, color='blue', label='Predicted vs Actual')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='Perfect Prediction')\n",
        "plt.xlabel('Actual Inspection Score')\n",
        "plt.ylabel('Predicted Inspection Score')\n",
        "plt.legend()\n",
        "plt.title('Random Forest Regressor: Actual vs Predicted Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GeNSGSc58ZfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Report as Heatmap**"
      ],
      "metadata": {
        "id": "0XRPWYICBh41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred_rfc, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_report.iloc[:-1, :-1], annot=True, cmap='coolwarm')\n",
        "plt.title('Random Forest Classifier - Classification Report')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YTHXp4nV8pFQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}